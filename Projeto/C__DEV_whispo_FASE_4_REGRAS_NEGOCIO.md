# FASE 4: REGRAS DE NEG√ìCIO E L√ìGICA CORE

## RESUMO EXECUTIVO

Whispo implementa l√≥gica de neg√≥cio principalmente em 3 √°reas: **(1) Captura e processamento de √°udio**, **(2) Integra√ß√£o com APIs externas**, e **(3) Gerenciamento de configura√ß√£o**. Notavelmente, **valida√ß√£o de entrada √© quase inexistente** ‚Äî n√£o h√° schema validation, regex de API keys, ou limites de tamanho. Isso √© uma oportunidade de melhoria importante.

**Valida√ß√µes Implementadas**: 4 (poucas)
**Valida√ß√µes Recomendadas**: 12 (gap importante)
**Transforma√ß√µes de Dados**: 3
**Algoritmos Propriet√°rios**: 2

---

## 1. VALIDA√á√ïES E SANITIZA√á√ÉO

### 1.1 Valida√ß√µes Atualmente Implementadas

#### **Regra V1: Verifica√ß√£o de Exist√™ncia de API Key**

| Aspecto | Detalhe |
|---------|---------|
| **Condi√ß√£o** | Quando usu√°rio tenta fazer transcri√ß√£o |
| **Valida√ß√£o** | `if (!config.openaiApiKey && config.sttProviderId === "openai")` |
| **A√ß√£o Resultante** | Enviar request mesmo assim (deixa API retornar 401) |
| **C√≥digo Fonte** | `tipc.ts` linhas ~120-130 (fetch endpoint com Authorization header) |
| **Tipo** | Verifica√ß√£o b√°sica (n√£o-preventiva) |
| **Criticidade** | üü° IMPORTANTE - deveria bloquear antes de enviar request |

**Implementa√ß√£o Atual:**
```typescript
// tipc.ts - createRecording procedure
const openaiApiKey = config.openaiApiKey;
// ‚ùå Sem verifica√ß√£o antes de usar
fetch(endpoint, {
  headers: {
    Authorization: `Bearer ${openaiApiKey}`  // undefined se n√£o configurado
  }
})
```

**Recomenda√ß√£o:**
```typescript
if (!config.openaiApiKey && config.sttProviderId === "openai") {
  throw new Error("OpenAI API key is required. Configure in Settings.")
}
```

---

#### **Regra V2: Verifica√ß√£o de Base URL Customizada**

| Aspecto | Detalhe |
|---------|---------|
| **Condi√ß√£o** | Quando usu√°rio define base URL customizada em settings |
| **Valida√ß√£o** | Nenhuma (usa valor diretamente) |
| **A√ß√£o Resultante** | Se URL malformado, fetch falhar√° silenciosamente |
| **C√≥digo Fonte** | `tipc.ts` linhas ~115-125 |
| **Tipo** | Sem valida√ß√£o |
| **Criticidade** | üî¥ CR√çTICO - usuario pode quebrar app com URL inv√°lida |

**Implementa√ß√£o Atual:**
```typescript
const groqBaseUrl = config.groqBaseUrl || "https://api.groq.com/openai/v1"
const openaiBaseUrl = config.openaiBaseUrl || "https://api.openai.com/v1"

const endpoint = `${baseUrl}/audio/transcriptions`
// ‚ùå Sem valida√ß√£o de URL
```

**Recomenda√ß√£o:**
```typescript
function validateApiUrl(url: string): boolean {
  try {
    const parsed = new URL(url)
    return parsed.protocol === 'https:' || parsed.protocol === 'http:'
  } catch {
    return false
  }
}

if (config.openaiBaseUrl && !validateApiUrl(config.openaiBaseUrl)) {
  throw new Error("Invalid OpenAI Base URL. Must be valid HTTPS URL.")
}
```

---

#### **Regra V3: Verifica√ß√£o de Permiss√£o de Acessibilidade (macOS)**

| Aspecto | Detalhe |
|---------|---------|
| **Condi√ß√£o** | Quando tentando inserir texto no app |
| **Valida√ß√£o** | `if (isAccessibilityGranted())` |
| **A√ß√£o Resultante** | Se falso, n√£o chama `writeText()` - texto fica em clipboard |
| **C√≥digo Fonte** | `tipc.ts` linhas ~185-190 |
| **Tipo** | Verifica√ß√£o preventiva |
| **Criticidade** | üü¢ BOM - fallback gracioso para clipboard |

**Implementa√ß√£o:**
```typescript
// tipc.ts - createRecording procedure
clipboard.writeText(transcript)
if (isAccessibilityGranted()) {
  await writeText(transcript)  // Only if permission granted
}
```

**Comportamento:**
- ‚úÖ Texto SEMPRE entra no clipboard (fallback seguro)
- ‚úÖ Keystroke simulation s√≥ se permitido
- ‚úÖ User pode Ctrl+V manualmente se keystroke falhar

---

#### **Regra V4: Try/Catch no JSON Config Load**

| Aspecto | Detalhe |
|---------|---------|
| **Condi√ß√£o** | Ao carregar arquivo de config na inicializa√ß√£o |
| **Valida√ß√£o** | Try/catch ao fazer `JSON.parse()` |
| **A√ß√£o Resultante** | Se arquivo corrompido, retorna `{}` (config vazia) |
| **C√≥digo Fonte** | `config.ts` linhas ~10-15 |
| **Tipo** | Error handling gracioso |
| **Criticidade** | üü¢ BOM - app n√£o crashes com config corrupta |

**Implementa√ß√£o:**
```typescript
// config.ts
const getConfig = () => {
  try {
    return JSON.parse(fs.readFileSync(configPath, "utf8")) as Config
  } catch {
    return {}  // ‚úÖ Fallback to empty config
  }
}
```

---

### 1.2 Valida√ß√µes Recomendadas (Gaps Importantes)

#### **Regra V5: Valida√ß√£o de Formato de API Key** ‚ùå N√ÉO IMPLEMENTADO

```
Input:  Qualquer string digitada pelo usu√°rio em "API Key" field
Rule:   API keys t√™m formato espec√≠fico por provider
        - OpenAI: "sk-" prefix, 48 caracteres
        - Groq: "gsk_" prefix, ~50 caracteres
        - Gemini: Base64 encoded, ~100 caracteres

Valida√ß√£o Esperada:
if (!config.openaiApiKey.startsWith("sk-")) {
  throw new Error("Invalid OpenAI API key format (must start with 'sk-')")
}

Criticidade: üü° IMPORTANTE - evita 401 errors depois
```

---

#### **Regra V6: Teste de Conectividade de API Key** ‚ùå N√ÉO IMPLEMENTADO

```
Input:  API Key ap√≥s usu√°rio pressionar Enter/Save
Action: Enviar request test para API com a key
        - OpenAI: GET /models (lista modelos dispon√≠veis)
        - Groq: GET /models
        - Gemini: GET /models

Resultado Esperado:
if (response.status === 401) {
  showErrorDialog("Invalid API key. Please check and try again.")
} else if (response.ok) {
  showSuccessToast("API key is valid!")
}

Criticidade: üî¥ CR√çTICO - permite user detectar key inv√°lida imediatamente
```

---

#### **Regra V7: Tamanho M√°ximo de √Åudio** ‚ùå N√ÉO IMPLEMENTADO

```
Input:  Blob de √°udio do recorder
Rule:   - Tamanho m√°ximo: 20 MB (limite OpenAI/Groq Whisper)
        - Dura√ß√£o m√°xima: 60 segundos (UX - ningu√©m quer gravar 1 min)

Valida√ß√£o:
if (blob.size > 20 * 1024 * 1024) {
  throw new Error("Audio file too large (max 20 MB)")
}

if (duration > 60000) {  // 60 segundos em ms
  throw new Error("Recording too long (max 60 seconds)")
}

Criticidade: üü° IMPORTANTE - evita failures silenciosos
```

---

#### **Regra V8: Tamanho M√≠nimo de √Åudio** ‚ùå N√ÉO IMPLEMENTADO

```
Input:  Duration da grava√ß√£o
Rule:   Dura√ß√£o m√≠nima: 0.5 segundos
        (Whisper necessita m√≠nimo de √°udio v√°lido)

Valida√ß√£o:
if (duration < 500) {  // 0.5 segundos
  throw new Error("Recording too short. Please record at least 0.5 seconds.")
}

Criticidade: üü¢ COMPLEMENTAR - melhora UX
```

---

#### **Regra V9: Sanitiza√ß√£o de Prompt LLM** ‚ùå N√ÉO IMPLEMENTADO

```
Input:  Prompt customizado definido pelo usu√°rio
Rule:   - M√°ximo 2000 caracteres
        - Deve conter placeholder {transcript}
        - Sem injection de ambiente (n√£o h√° risco real mas seria bom)

Valida√ß√£o:
if (!config.transcriptPostProcessingPrompt.includes("{transcript}")) {
  throw new Error("Prompt must include {transcript} placeholder")
}

if (config.transcriptPostProcessingPrompt.length > 2000) {
  throw new Error("Prompt too long (max 2000 characters)")
}

Criticidade: üü° IMPORTANTE - evita prompts quebrados
```

---

#### **Regra V10: Valida√ß√£o de Idioma** ‚ùå N√ÉO IMPLEMENTADO

```
Input:  Idioma selecionado (quando implementado)
Rule:   Apenas idiomas suportados por Whisper:
        en, es, fr, de, ja, ko, zh, pt, ar, hi, ru, etc

Status Atual:
- N√£o h√° UI de sele√ß√£o de idioma
- Whisper usa default (ingl√™s)
- Poderia ser adicionado ao Config

Criticidade: üü¢ COMPLEMENTAR - feature futura
```

---

#### **Regra V11: Limite de Rate Limiting Client-Side** ‚ùå N√ÉO IMPLEMENTADO

```
Rule:   N√£o permitir enviar m√∫ltiplas transcri√ß√µes em paralelo
        (API pode rejeitar com 429 Rate Limit)

Implementa√ß√£o Esperada:
const transcriptionQueue = []
const isTranscribing = ref(false)

async function queueTranscription(blob) {
  if (isTranscribing.value) {
    transcriptionQueue.push(blob)
    return
  }
  
  isTranscribing.value = true
  try {
    await transcribe(blob)
  } finally {
    isTranscribing.value = false
    if (transcriptionQueue.length > 0) {
      queueTranscription(transcriptionQueue.shift())
    }
  }
}

Criticidade: üü° IMPORTANTE - previne cascata de erros
```

---

#### **Regra V12: Valida√ß√£o de Resposta Whisper** ‚ùå PARCIALMENTE IMPLEMENTADO

```
Input:  Response JSON da API Whisper
Rule:   - Campo "text" deve existir
        - N√£o deve estar vazio

Implementa√ß√£o Atual:
const json: { text: string } = await response.json()
const transcript = json.text

‚ùå Sem verifica√ß√£o se json.text existe ou est√° vazio

Recomenda√ß√£o:
if (!json.text || typeof json.text !== 'string') {
  throw new Error("Invalid Whisper response: missing transcript")
}

if (json.text.trim() === "") {
  // Pode ser √°udio com apenas sil√™ncio
  throw new Error("Whisper returned empty transcription. Recording may be too quiet.")
}

Criticidade: üü° IMPORTANTE - melhora error messages
```

---

### 1.3 Tabela Consolidada de Valida√ß√µes

| ID | Valida√ß√£o | Status | Severidade | Localiza√ß√£o | Recomenda√ß√£o |
|----|-----------|--------|-----------|------------|--------------|
| V1 | API key existe | ‚úÖ Implementado | üü° Important | tipc.ts | Bloquear antes de request |
| V2 | Base URL v√°lida | ‚ùå Ausente | üî¥ Critical | tipc.ts | Validar com new URL() |
| V3 | Permiss√£o Accessibility | ‚úÖ Implementado | üü¢ Good | tipc.ts | Mant√©m como est√° |
| V4 | Config JSON parse | ‚úÖ Implementado | üü¢ Good | config.ts | Mant√©m como est√° |
| V5 | API key formato | ‚ùå Ausente | üü° Important | settings | Regex por provider |
| V6 | API key conectividade | ‚ùå Ausente | üî¥ Critical | settings | Test call ao salvar |
| V7 | Tamanho m√°x √°udio | ‚ùå Ausente | üü° Important | panel.tsx | Checkar antes de upload |
| V8 | Tamanho m√≠n √°udio | ‚ùå Ausente | üü¢ Nice-to-have | panel.tsx | Checkar duration |
| V9 | Sanitiza√ß√£o prompt LLM | ‚ùå Ausente | üü° Important | settings | Validar placeholder |
| V10 | Idioma suportado | ‚ùå N/A | üü¢ Feature-future | ‚Äî | Para feature de idioma |
| V11 | Rate limit client-side | ‚ùå Ausente | üü° Important | tipc.ts | Queue de requests |
| V12 | Resposta Whisper v√°lida | ‚ö†Ô∏è Parcial | üü° Important | tipc.ts | Validar json.text |

---

## 2. TRANSFORMA√á√ïES DE DADOS

### 2.1 Transforma√ß√£o 1: Captura de √Åudio ‚Üí WebM Blob

**Ponto de Entrada**: `recorder.ts - startRecording()`

```
Input:  MediaStream (√°udio raw do microfone)
Process:
  1. navigator.mediaDevices.getUserMedia({audio: {deviceId: "default"}})
  2. new MediaRecorder(stream, {audioBitsPerSecond: 128e3})
     - Codec: OPUS (padr√£o em navegadores, recomendado W3C)
     - Container: WebM (formato aberto, suporta OPUS)
     - Bitrate: 128 kbps (balan√ßo qualidade/tamanho)
     - Amostragem: Browser default (~48 kHz)
  3. mediaRecorder.start()
  4. mediaRecorder.ondataavailable(): coleta chunks em Array
  5. new Blob(chunks, {type: "audio/webm"})
Output: Blob {type: "audio/webm", size: ~100KB para 10s de fala}
```

**C√≥digo:**
```typescript
// recorder.ts
mediaRecorder = new MediaRecorder(stream, {
  audioBitsPerSecond: 128e3  // 128 kbps OPUS
})

mediaRecorder.ondataavailable = (event) => {
  audioChunks.push(event.data)
}

mediaRecorder.onstop = async () => {
  blob = new Blob(audioChunks, {type: mediaRecorder.mimeType})
  this.emit("record-end", blob, duration)
}
```

**Justificativas:**
- ‚úÖ WebM + OPUS escolha padr√£o W3C (compat√≠vel com Whisper)
- ‚úÖ 128 kbps ideal (20KB/sec, 10s ~= 200KB)
- ‚úÖ Sem pr√©-processamento (Whisper preferencia)
- ‚ùå Sem redu√ß√£o de ru√≠do (deixa para Whisper fazer)
- ‚ùå Sem normaliza√ß√£o de volume (Whisper robusto a varia√ß√£o)

---

### 2.2 Transforma√ß√£o 2: Visualizador RMS (Sound Level Display)

**Ponto de Entrada**: `recorder.ts - analyseAudio()`

```
Input:  MediaStream (√°udio do microfone)
Process:
  1. AudioContext.createMediaStreamSource(stream)
  2. Analyser.getByteTimeDomainData() [1024 ou 2048 samples]
  3. Calcular RMS (Root Mean Square) dos samples
     RMS = sqrt(sum(x¬≤) / N)
  4. Normalizar RMS para 0-1 range
     - Multiplicar por 10 (amplificar porque valores pequenos)
     - Aplicar expoente 1.5 (compress√£o n√£o-linear)
     - Clamp entre 0.01 e 1.0
  5. Renderizar barra vertical com altura proporcional ao RMS
Output: number (0.01 a 1.0) ‚Üí height no visualizador
```

**C√≥digo Detalhado:**
```typescript
const calculateRMS = (data: Uint8Array) => {
  let sumSquares = 0
  for (let i = 0; i < data.length; i++) {
    const normalizedValue = (data[i] - 128) / 128  // Convert to signed [-1, 1]
    sumSquares += normalizedValue * normalizedValue
  }
  return Math.sqrt(sumSquares / data.length)
}

const normalizeRMS = (rms: number) => {
  rms = rms * 10  // Amplify
  const exp = 1.5  // Non-linear compression
  const scaledRMS = Math.pow(rms, exp)
  return Math.min(1.0, Math.max(0.01, scaledRMS))  // Clamp [0.01, 1.0]
}
```

**Visualiza√ß√£o em panel.tsx:**
```typescript
{visualizerData.map((rms, index) => (
  <div
    style={{
      height: `${Math.min(100, Math.max(16, rms * 100))}%`
    }}
  />
))}
```

**Transforma√ß√£o da altura:**
- RMS 0.01 ‚Üí 16px (m√≠nimo visual)
- RMS 0.5 ‚Üí 50px
- RMS 1.0 ‚Üí 100px (m√°ximo)

**Justificativas:**
- ‚úÖ RMS √© m√©trica padr√£o de n√≠vel de √°udio
- ‚úÖ Expoente 1.5 d√° visual responsivo (n√£o linear)
- ‚úÖ Clamping evita barras muito pequenas/grandes
- ‚ö†Ô∏è Sem detec√ß√£o de sil√™ncio (seria bom implementar)

---

### 2.3 Transforma√ß√£o 3: Texto ‚Üí FormData Multipart

**Ponto de Entrada**: `tipc.ts - createRecording()`

```
Input:  ArrayBuffer (blob.arrayBuffer())
Process:
  1. Converter para File object (Whisper necessita)
     new File([buffer], "recording.webm", {type: "audio/webm"})
  2. Criar FormData (multipart/form-data)
  3. Append fields:
     - file: File object (body do audio)
     - model: String ("whisper-1" ou "whisper-large-v3")
     - response_format: "json"
  4. fetch() com m√©todo POST + headers Auth
Output: FormData pronto para POST
```

**C√≥digo:**
```typescript
const form = new FormData()

form.append(
  "file",
  new File([input.recording], "recording.webm", {type: "audio/webm"})
)

form.append(
  "model",
  config.sttProviderId === "groq" ? "whisper-large-v3" : "whisper-1"
)

form.append("response_format", "json")

const response = await fetch(`${baseUrl}/audio/transcriptions`, {
  method: "POST",
  headers: {
    Authorization: `Bearer ${apiKey}`
    // ‚ùå Content-Type √© auto-set por FormData
  },
  body: form
})
```

**Sele√ß√£o de Modelo:**
- OpenAI: "whisper-1" (mais r√°pido, menor lat√™ncia)
- Groq: "whisper-large-v3" (modelo maior, mais preciso)

**Justificativas:**
- ‚úÖ FormData √© padr√£o REST para upload de arquivos
- ‚úÖ Modelo Groq √© "large" (melhor qual. vs OpenAI "tiny/base")
- ‚ö†Ô∏è Sem compression de √°udio (Whisper aceita at√© 25MB)

---

### 2.4 Transforma√ß√£o 4: Transcri√ß√£o ‚Üí P√≥s-Processamento LLM

**Ponto de Entrada**: `llm.ts - postProcessTranscript()`

```
Input:  String (ex: "hello world thats great")
Process:
  1. Verificar se p√≥s-processamento est√° ativado
  2. Recuperar prompt template do usu√°rio
  3. Substituir placeholder {transcript} no prompt
     Prompt exemplo: "Fix grammar and punctuation:\n\n{transcript}"
     Resultado: "Fix grammar and punctuation:\n\nhello world thats great"
  4. Enviar para LLM (OpenAI/Groq/Gemini)
  5. Extrair texto de response (provider-specific parsing)
Output: String (ex: "Hello, world! That's great.")
```

**C√≥digo:**
```typescript
// llm.ts - postProcessTranscript
const prompt = config.transcriptPostProcessingPrompt.replace(
  "{transcript}",
  transcript
)

if (providerId === "gemini") {
  const gai = new GoogleGenerativeAI(config.geminiApiKey)
  const gModel = gai.getGenerativeModel({model: "gemini-1.5-flash-002"})
  const result = await gModel.generateContent([prompt])
  return result.response.text().trim()
}

else {  // OpenAI or Groq
  const response = await fetch(`${baseUrl}/chat/completions`, {
    method: "POST",
    body: JSON.stringify({
      temperature: 0,
      model: chatModel,
      messages: [{
        role: "system",
        content: prompt
      }]
    })
  })
  
  const json = await response.json()
  return json.choices[0].message.content.trim()
}
```

**Template Customiz√°vel:**
- Usu√°rio define no Settings ‚Üí "Transcript Post-Processing" ‚Üí "Prompt"
- Exemplo padr√£o (n√£o implementado, user precisa digitar):
  ```
  Fix grammar and capitalization. Keep original meaning:
  
  {transcript}
  ```

**Parsing Provider-Specific:**
- Gemini: `result.response.text()`
- OpenAI/Groq: `json.choices[0].message.content`

---

### 2.5 Fluxograma de Transforma√ß√µes de Dados

```mermaid
flowchart TD
    A["üéôÔ∏è Microfone (Raw Audio Stream)"]
    B["üìä MediaRecorder API"]
    C["üîß OPUS Codec + WebM Container<br/>128 kbps"]
    D["üì¶ Blob Array ‚Üí Blob Object<br/>audio/webm"]
    
    E["üì° Whisper API Request<br/>FormData Multipart"]
    F["üåê OpenAI/Groq API"]
    G["üìÑ JSON Response<br/>{text: 'transcribed'}"]
    
    H{"LLM Post-Processing<br/>Enabled?"}
    I["üß† LLM API Request<br/>Chat Completions"]
    J["üåê OpenAI/Groq/Gemini"]
    K["üìù Processed Text<br/>{choices[0].message.content}"]
    
    L["üìã Clipboard Write"]
    M["‚å®Ô∏è Keystroke Simulation<br/>via whispo-rs"]
    N["‚úÖ Text in Focused App"]
    
    A -->|Record 10-60s| B
    B -->|Chunks| C
    C -->|Combine| D
    D -->|arrayBuffer| E
    E -->|POST /audio/transcriptions| F
    F -->|200 OK| G
    
    G -->|extract .text| H
    H -->|No| L
    H -->|Yes| I
    I -->|POST /chat/completions| J
    J -->|200 OK| K
    K -->|extract content| L
    
    L -->|setText| M
    M -->|enigo::text()| N
    
    style A fill:#4f46e5
    style D fill:#4f46e5
    style G fill:#10b981
    style K fill:#10b981
    style N fill:#f59e0b
```

---

## 3. CONFIGURA√á√ïES E POL√çTICAS

### 3.1 Pol√≠tica de Providers

**STT (Speech-to-Text) Providers:**

```
Provider: OpenAI Whisper
  - Models: whisper-1
  - Endpoint: https://api.openai.com/v1/audio/transcriptions
  - Cost: $0.006 per minute
  - Speed: ~5-10 seconds for 30s audio
  - Accuracy: Excellent
  - Default: Yes
  - Code Location: shared/index.ts (STT_PROVIDERS)

Provider: Groq Whisper (via Groq API)
  - Models: whisper-large-v3
  - Endpoint: https://api.groq.com/openai/v1/audio/transcriptions
  - Cost: Free tier available
  - Speed: Fast (~2-3 seconds for 30s audio)
  - Accuracy: Good
  - Default: No
  - Code Location: shared/index.ts (STT_PROVIDERS)

UI Selection: pages/settings-general.tsx
  - Dropdown para selecionar STT provider
  - Fallback: OpenAI (se sttProviderId n√£o definido)
```

**Chat (LLM) Providers:**

```
Provider: OpenAI
  - Models: gpt-4o-mini
  - Purpose: Post-processing de transcri√ß√£o
  - Endpoint: https://api.openai.com/v1/chat/completions
  - Cost: $0.00015 per 1K input tokens
  - Temperature: 0 (determin√≠stico)
  - Code: tipc.ts (llm.ts), lines ~40-60

Provider: Groq
  - Models: llama-3.1-70b-versatile
  - Purpose: Post-processing de transcri√ß√£o
  - Endpoint: https://api.groq.com/openai/v1/chat/completions
  - Cost: Free
  - Temperature: 0 (determin√≠stico)
  - Code: tipc.ts (llm.ts), lines ~40-60

Provider: Google Gemini
  - Models: gemini-1.5-flash-002
  - Purpose: Post-processing de transcri√ß√£o
  - Endpoint: https://generativelanguage.googleapis.com
  - Cost: Free tier available
  - Code: tipc.ts (llm.ts), lines ~30-38

UI Selection: pages/settings-general.tsx
  - Dropdown para p√≥s-processamento provider
  - Fallback: OpenAI (se n√£o definido)
```

**C√≥digo de Sele√ß√£o:**
```typescript
// shared/index.ts
export const STT_PROVIDERS = [
  { label: "OpenAI", value: "openai" },
  { label: "Groq", value: "groq" }
] as const

export const CHAT_PROVIDERS = [
  { label: "OpenAI", value: "openai" },
  { label: "Groq", value: "groq" },
  { label: "Gemini", value: "gemini" }
] as const

// settings-general.tsx - UI
<Select
  defaultValue={sttProviderId}
  onValueChange={(value) => saveConfig({sttProviderId: value})}
>
  {STT_PROVIDERS.map(p => (
    <SelectItem key={p.value} value={p.value}>
      {p.label}
    </SelectItem>
  ))}
</Select>
```

---

### 3.2 Pol√≠tica de Armazenamento de Dados

**Localiza√ß√£o de Dados:**

```
Base Directory: {appData}/whispo
  Windows: C:\Users\{user}\AppData\Roaming\io.github.egoist.whispo
  macOS: ~/Library/Application Support/io.github.egoist.whispo
  Linux: ~/.config/io.github.egoist.whispo

Estrutura:
‚îú‚îÄ‚îÄ config.json (configura√ß√£o do usu√°rio)
‚îú‚îÄ‚îÄ recordings/ (hist√≥rico de grava√ß√µes)
‚îÇ   ‚îú‚îÄ‚îÄ history.json (metadados)
‚îÇ   ‚îú‚îÄ‚îÄ {timestamp1}.webm (arquivo de √°udio)
‚îÇ   ‚îú‚îÄ‚îÄ {timestamp2}.webm
‚îÇ   ‚îî‚îÄ‚îÄ ...
```

**Config Storage Policy:**

```
File: config.json
Format: JSON simples (sem encripta√ß√£o)
Size: ~2-5 KB

Contents:
{
  "shortcut": "hold-ctrl" | "ctrl-slash",
  "hideDockIcon": boolean (macOS only),
  "sttProviderId": "openai" | "groq",
  "openaiApiKey": "sk-...",
  "openaiBaseUrl": "https://api.openai.com/v1",
  "groqApiKey": "gsk_...",
  "groqBaseUrl": "https://api.groq.com/openai/v1",
  "geminiApiKey": "...",
  "geminiBaseUrl": "https://generativelanguage.googleapis.com",
  "transcriptPostProcessingEnabled": boolean,
  "transcriptPostProcessingProviderId": "openai" | "groq" | "gemini",
  "transcriptPostProcessingPrompt": string
}

Seguran√ßa: ‚ö†Ô∏è Sem encripta√ß√£o
  - API keys armazenados em plain text
  - Risco: Se m√°quina comprometida, keys expostas
  - Recomenda√ß√£o: Usar electron.safeStorage para encriptar
```

**Recordings Storage Policy:**

```
history.json
  - Array de RecordingHistoryItem
  - Salvo ap√≥s cada transcri√ß√£o bem-sucedida
  - Nunca deletado automaticamente
  - Deletion via UI: "Settings" ‚Üí "Data" ‚Üí "Delete All"

Format:
[
  {
    "id": "1735814400000",  // Date.now()
    "createdAt": 1735814400000,
    "duration": 10500,  // milliseconds
    "transcript": "hello world this is a test"
  },
  ...
]

Audio Files:
  - Nome: {id}.webm (ex: 1735814400000.webm)
  - Formato: WebM Opus (original da captura)
  - Reten√ß√£o: Indefinida (at√© user deletar)
  - Size: ~10-20 KB per 10 seconds de fala

Carregamento:
  - Em memory (React Query)
  - Renderizado em pages/index.tsx
  - Suporta playback via <audio> tag
  - Protocolo customizado: assets://recording/{id}
```

---

### 3.3 Pol√≠tica de Cache

**Cache de Configura√ß√£o:**

```
Location: React Query queryClient
Key: ["config"]
TTL: Infinite (cache at√© invalidar manualmente)
Invalidation: tipcClient.saveConfig() ‚Üí queryClient.invalidateQueries({queryKey: ["config"]})

Behavior:
- Query carrega config uma vez na inicializa√ß√£o
- Todas as pages veem mesma vers√£o (React Query cache)
- Ao salvar settings, query √© invalidada e refetched
```

**Cache de Hist√≥rico de Grava√ß√µes:**

```
Location: React Query queryClient
Key: ["recording-history"]
TTL: Infinite
Invalidation: 
  - Ap√≥s createRecording (novo item)
  - Ap√≥s deleteRecordingItem
  - Ap√≥s deleteRecordingHistory

Behavior:
- Query carrega hist√≥rico do history.json
- Renderizado em pages/index.tsx
- Sorted descending by createdAt
```

**Cache de Status de Microfone:**

```
Location: React Query queryClient
Key: ["microphone-status"]
TTL: Infinite
Invalidation: Manual (n√£o refetch autom√°tico)

Behavior:
- Query chama tipcClient.getMicrophoneStatus()
- Usado em pages/setup.tsx
- ‚ö†Ô∏è N√£o refetch quando user muda permiss√£o em System Settings
- Recomenda√ß√£o: Refetch ao app retorna do background
```

---

### 3.4 Pol√≠tica de Telemetria e Logging

**Telemetria:**

```
Status: ‚ùå NENHUMA telemetria implementada
  - Sem Google Analytics
  - Sem Sentry
  - Sem rastreamento de uso
  - Sem tracking de erros
  - Privacidade garantida (dados ficam locais)

Recomenda√ß√£o:
  - Adicionar opt-in para error tracking (Sentry)
  - User nunca compartilha dados a menos que expl√≠citamente aceitar
```

**Logging:**

```
Console Logs: ‚úÖ Implementados
  - keyboard.ts: console.log("start recording", "release ctrl", etc)
  - recorder.ts: logTime() function para performance monitoring
  - tipc.ts: console.log(chatJson) para response inspection

File Logging: ‚ùå N√£o implementado
  - Nenhum log arquivo persistente
  - Logs perdidos ao fechar app
  - Dif√≠cil debug ap√≥s crashes

Recomenda√ß√£o:
  - Implementar file logging com winston ou similar
  - Arquivar logs por data (7 dias de retention)
  - Incluir em error reports
```

---

## 4. ALGORITMOS PROPRIET√ÅRIOS

### 4.1 Algoritmo 1: M√°quina de Estados de Hotkey Detection

**Prop√≥sito:** Detectar quando usu√°rio segura Ctrl e diferencia entre "hold to record" e "press other key"

**Estados:**

```
idle:
  - isHoldingCtrlKey = false
  - isPressedCtrlKey = false
  - startRecordingTimer = undefined

waiting (800ms):
  - User segura Ctrl
  - Timer iniciado (800ms)
  - Se outro key pressionado ‚Üí cancela timer
  - Se Ctrl liberado antes de 800ms ‚Üí volta idle

holding:
  - 800ms completou
  - isHoldingCtrlKey = true
  - Panel window aparece
  - Grava√ß√£o inicia

recording:
  - User tem Ctrl pressionado
  - Se outro key pressionado ‚Üí cancela grava√ß√£o
  - Se Ctrl liberado ‚Üí finaliza grava√ß√£o

Transitions:
idle ‚Üí waiting: Ctrl pressed (setTimeout 800ms)
waiting ‚Üí idle: Ctrl released OR other key pressed
waiting ‚Üí holding: 800ms timer fires
holding ‚Üí idle: Ctrl released (finishRecording)
holding ‚Üí idle: Other key pressed (stopRecording)
```

**C√≥digo:**

```typescript
// keyboard.ts - handleEvent()
if (e.event_type === "KeyPress") {
  if (e.data.key === "ControlLeft") {
    isPressedCtrlKey = true
    
    if (hasRecentKeyPress()) return  // Other keys in last 10s?
    
    if (startRecordingTimer) return  // Already waiting?
    
    // Start waiting (800ms)
    startRecordingTimer = setTimeout(() => {
      isHoldingCtrlKey = true  // Transition to holding
      showPanelWindowAndStartRecording()
    }, 800)
  }
  
  else {  // Other key pressed
    keysPressed.set(e.data.key, timestamp)
    clearTimeout(startRecordingTimer)  // Cancel waiting
    
    if (isHoldingCtrlKey) {
      stopRecordingAndHidePanelWindow()  // Cancel recording
    }
    
    isHoldingCtrlKey = false  // Transition to idle
  }
}

else if (e.event_type === "KeyRelease") {
  if (e.data.key === "ControlLeft") {
    isPressedCtrlKey = false
    
    if (isHoldingCtrlKey) {
      rendererHandlers.finishRecording.send()  // End recording
    } else {
      stopRecordingAndHidePanelWindow()  // Cancel waiting
    }
    
    isHoldingCtrlKey = false  // Transition to idle
  }
}
```

**Caracter√≠sticas Especiais:**

```
1. Anti-bounce (hasRecentKeyPress):
   - Ignora Ctrl se outro key pressionado nos √∫ltimos 10s
   - Evita triggers acidentais (ex: Ctrl+C, Ctrl+V)

2. Timeout para KeyRelease:
   - Se KeyRelease event perdido (bug OS), key fica em map
   - Cleanup: keysPressed.clear() ap√≥s writeText()
   - Timeout autom√°tico: 10 segundos (fallback)

3. Dual Mode:
   - Default: Hold Ctrl (mode 1)
   - Config: Ctrl+/ (mode 2)
   - Mode 2 √© toggle, n√£o hold-to-record
```

---

### 4.2 Algoritmo 2: Normaliza√ß√£o de RMS para Visualizador

**Prop√≥sito:** Converter n√≠veis de √°udio bruto em barra visual responsiva

**F√≥rmula:**

```
Step 1: Extrair amostras em tempo real
  timeDomainData = Uint8Array (1024 ou 2048 samples)
  Range: [0, 255] (unsigned bytes)

Step 2: Normalizar para signed range
  normalizedValue = (sample - 128) / 128
  Range: [-1, 1]

Step 3: Calcular RMS (Root Mean Square)
  sumSquares = sum(normalizedValue¬≤)
  rms = sqrt(sumSquares / N)
  Range: [0, ~0.7] (tipicamente)

Step 4: Amplificar e comprimir
  rms = rms * 10  // Amplify [0, ~7]
  rms = rms ^ 1.5  // Non-linear compression [0, ~13]
  
  Exemplo de valores ap√≥s passo 4:
  - Sil√™ncio: ~0.1
  - Fala normal: ~0.5-2
  - Fala alta: ~5-10

Step 5: Normalizar para [0.01, 1.0]
  rms = clamp(rms, 0.01, 1.0)
  
  0.01 ‚Üí 1% (barra m√≠nima)
  1.0 ‚Üí 100% (barra m√°xima)

Step 6: Mapear para altura CSS
  height = rms * 100 + "px"  // [16px, 100px]
  
  Clamped: max(16px, min(100px, height))
```

**Justificativa do Expoente 1.5:**

```
Linear (expoente 1.0):
  rms: 0 ‚Üí height: 0
  rms: 0.5 ‚Üí height: 50
  rms: 1.0 ‚Üí height: 100
  Problema: Pouca diferen√ßa visual entre 0 e 0.5

Quadr√°tico (expoente 2.0):
  rms: 0 ‚Üí height: 0
  rms: 0.5 ‚Üí height: 25
  rms: 1.0 ‚Üí height: 100
  Problema: Muito agrupado em cima

Expoente 1.5 (Goldilocks):
  rms: 0 ‚Üí height: 0
  rms: 0.25 ‚Üí height: ~4
  rms: 0.5 ‚Üí height: ~18
  rms: 0.75 ‚Üí height: ~48
  rms: 1.0 ‚Üí height: 100
  Benef√≠cio: Distribui√ß√£o visual uniforme
```

---

## 5. AN√ÅLISE DE PROMPTS LLM

### 5.1 Prompts Customiz√°veis

**Status:** ‚úÖ Prompts s√£o customiz√°veis pelo usu√°rio

**UI para Editar Prompt:**

```typescript
// pages/settings-general.tsx
<Control label="Prompt" className="px-3">
  <Dialog>
    <DialogTrigger asChild>
      <Button size="sm" variant="outline">Edit</Button>
    </DialogTrigger>
    <DialogContent>
      <DialogTitle>Edit Prompt</DialogTitle>
      <Textarea
        rows={10}
        defaultValue={config.transcriptPostProcessingPrompt}
        onChange={(e) => {
          saveConfig({
            transcriptPostProcessingPrompt: e.target.value
          })
        }}
      />
      <div className="text-sm text-muted-foreground">
        Use <span className="select-text">{{"{transcript}"}}</span> placeholder to insert transcript
      </div>
    </DialogContent>
  </Dialog>
</Control>
```

**Execu√ß√£o do Prompt:**

```typescript
// llm.ts - postProcessTranscript
const prompt = config.transcriptPostProcessingPrompt
  .replace("{transcript}", transcript)

// Enviado como system message
const messages = [
  {
    role: "system",
    content: prompt
  }
]
```

---

### 5.2 Prompts Padr√£o Sugeridos (N√£o Implementados)

**N√£o h√° templates padr√£o no c√≥digo. Usu√°rio deve escrever do zero.**

**Exemplos que Funcionariam Bem:**

#### Prompt 1: Corre√ß√£o Gramatical
```
Fix all grammar and spelling errors in the following text. Keep the original meaning and tone. Only output the corrected text, nothing else:

{transcript}
```

Expected Output:
```
Input:  "hello world thats great im so happy"
Output: "Hello, world! That's great. I'm so happy."
```

---

#### Prompt 2: Formata√ß√£o de Conversa√ß√£o
```
This is a transcribed conversation. Format it with proper capitalization, punctuation, and line breaks for readability. Add speaker labels if identifiable:

{transcript}
```

Expected Output:
```
Input:  "hey john how are you im doing great thanks for asking"
Output: 
"Hey John, how are you?
I'm doing great, thanks for asking!"
```

---

#### Prompt 3: Extra√ß√£o de Pontos-Chave
```
Extract the main action items or key points from the following transcript. Format as a numbered list:

{transcript}
```

Expected Output:
```
Input:  "we need to call the client on monday then send them the proposal by wednesday and schedule a follow up for next week"
Output:
"1. Call the client on Monday
2. Send proposal by Wednesday
3. Schedule follow-up for next week"
```

---

#### Prompt 4: Tradu√ß√£o (se multi-l√≠ngua)
```
Translate the following text to English:

{transcript}
```

Expected Output:
```
Input:  "bonjour comment allez vous"
Output: "Hello, how are you?"
```

---

## 6. EDGE CASES E COMPORTAMENTOS ESPECIAIS

### 6.1 Edge Case 1: √Åudio Muito Curto (<1 segundo)

```
Cen√°rio: Usu√°rio segura Ctrl por < 1 segundo
Input Duration: 500ms
Result Path:
  1. panel.tsx: duration < 500ms
  2. Blob enviado mesmo assim para Whisper
  3. Whisper: ‚ùå Pode retornar texto vazio ou erro

Recomenda√ß√£o:
  if (duration < 500) {
    showWarning("Recording too short")
    return  // Don't send to API
  }
```

---

### 6.2 Edge Case 2: √Åudio Muito Longo (>60 segundos)

```
Cen√°rio: Usu√°rio esquece de liberar Ctrl
Input Duration: 120 segundos
Input Size: ~2-4 MB
Result Path:
  1. FormData enviado com √°udio de 120s
  2. Whisper API: ‚úÖ Processa (limite √© 25 MB)
  3. Resposta: Texto com transcri√ß√£o completa
  4. Panel.tsx: transcribeMutation.isPending = true (UI bloqueada)

Problema: User quer cancelar mas can't (sem bot√£o de cancel)

Recomenda√ß√£o:
  1. Adicionar m√°ximo de 60 segundos
  2. Se usu√°rio tenta gravar mais, mostrar warning
  3. Auto-stop ap√≥s 60s
```

---

### 6.3 Edge Case 3: M√∫ltiplos Idiomas no Mesmo √Åudio

```
Cen√°rio: "Hello, comment √ßa va? ‰Ω†Â•Ω"
Whisper Response: Mescla idiomas no output
Output: "Hello, comment √ßa va? You how"
Problem: Tradu√ß√£o incorreta, mistura idiomas

Status: Sem tratamento especial
Recomenda√ß√£o:
  - Adicionar sele√ß√£o de idioma em settings
  - Passar language param ao Whisper API
  - Documentar que Whisper funciona melhor com idioma √∫nico
```

---

### 6.4 Edge Case 4: Ru√≠do Excessivo

```
Cen√°rio: Background muito barulhento
Whisper Response: "hxjdka lkajsd jsaklj" (gibberish)
Problem: Sem valida√ß√£o de qualidade

Status: Sem tratamento
Recomendation:
  1. Implementar Voice Activity Detection (VAD) pr√©-transcri√ß√£o
  2. Rejeitar √°udio com SNR (Signal-to-Noise Ratio) muito baixo
  3. Ou: Permitir user decidir via flag "was this audio clear?"
```

---

### 6.5 Edge Case 5: Permiss√£o de Acessibilidade Revogada Mid-Session

```
Cen√°rio: 
  1. App rodando com accessibility granted
  2. User vai em System Settings e revoga acesso
  3. User segura Ctrl para gravar
  4. Transcri√ß√£o completa, tenta writeText()

Result Path:
  1. isAccessibilityGranted() ‚Üí false (verifica√ß√£o no momento)
  2. Pula writeText()
  3. Texto fica s√≥ em clipboard
  4. User pode fazer Ctrl+V

Status: ‚úÖ Tratado corretamente (fallback a clipboard)
```

---

### 6.6 Edge Case 6: API Key Alterada Entre Requests

```
Cen√°rio:
  1. User inicia grava√ß√£o com API key A
  2. Enquanto est√° gravando, user abre Settings
  3. User troca para API key B
  4. Grava√ß√£o termina, tenta enviar com key B

Result Path:
  1. createRecording() l√™ config.openaiApiKey
  2. Pega valor atual (B)
  3. Whisper processa com key B
  4. ‚úÖ Funciona (sem race condition)

Status: ‚úÖ Sem problema (config √© sincronizado)
```

---

### 6.7 Edge Case 7: LLM Post-Processing com Prompt Inv√°lido

```
Cen√°rio: User define prompt sem placeholder {transcript}
Prompt: "Fix this text:"
Transcript: "hello world"
Resultado: "Fix this text:" √© enviado, {transcript} nunca √© substitu√≠do

Result:
  LLM recebe: "Fix this text:" (sem o √°udio!)
  LLM responde: "I need the text to fix"
  User v√™: Resposta gen√©rica, n√£o corrigida

Status: ‚ùå Sem valida√ß√£o
Recomenda√ß√£o: V9 na tabela de valida√ß√µes (acima)
```

---

### 6.8 Edge Case 8: Network Timeout Durante Whisper API

```
Cen√°rio: Conex√£o de internet cai enquanto enviando √°udio
Status Code: Nenhum (timeout/connection reset)

Result Path:
  1. fetch() lan√ßa AbortError ou timeout
  2. tipcClient.createRecording() n√£o tem try/catch? ‚ö†Ô∏è
  3. Promise rejeita
  4. panel.tsx: transcribeMutation.onError() dispara
  5. displayError() mostra ao user

Status: ‚ö†Ô∏è Parcialmente tratado (sem retry)
Recomenda√ß√£o: Implementar retry com backoff (Prioridade 1)
```

---

## 7. TABELA RESUMIDA DE REGRAS DE NEG√ìCIO

| Tipo | Regra | Status | Severidade | C√≥digo |
|------|-------|--------|-----------|--------|
| **Valida√ß√£o** | API key existe | ‚úÖ | üü° | tipc.ts |
| | Base URL v√°lida | ‚ùå | üî¥ | tipc.ts |
| | Permiss√£o Accessibility | ‚úÖ | üü¢ | tipc.ts |
| | Config JSON parse | ‚úÖ | üü¢ | config.ts |
| | Tamanho m√°x √°udio | ‚ùå | üü° | panel.tsx |
| | Tamanho m√≠n √°udio | ‚ùå | üü¢ | recorder.ts |
| **Transforma√ß√£o** | √Åudio ‚Üí WebM | ‚úÖ | ‚Äî | recorder.ts |
| | Visualizador RMS | ‚úÖ | ‚Äî | recorder.ts |
| | Blob ‚Üí FormData | ‚úÖ | ‚Äî | tipc.ts |
| | Texto ‚Üí LLM | ‚úÖ | ‚Äî | llm.ts |
| **Algoritmo** | Hotkey State Machine | ‚úÖ | ‚Äî | keyboard.ts |
| | RMS Normalization | ‚úÖ | ‚Äî | recorder.ts |
| **Config** | STT Provider Selection | ‚úÖ | ‚Äî | shared/index |
| | LLM Provider Selection | ‚úÖ | ‚Äî | shared/index |
| | Data Retention Policy | ‚úÖ (indefinida) | ‚Äî | tipc.ts |

---

## 8. CONCLUS√ïES E RECOMENDA√á√ïES

### Valida√ß√µes Implementadas: 4/12 (33%)

- ‚úÖ Config JSON parsing (gracioso)
- ‚úÖ API key existence check (b√°sico)
- ‚úÖ Accessibility permission guard (bom)
- ‚úÖ Try/catch no filesystem (bom)

- ‚ùå Faltam 8 valida√ß√µes cr√≠ticas (API key format, conectividade, tamanho, etc)

### Transforma√ß√µes Bem Implementadas

- ‚úÖ WebM @ 128 kbps √© padr√£o inteligente
- ‚úÖ RMS normalization com expoente 1.5 √© sofisticado
- ‚úÖ FormData multipart √© correto para Whisper API

### Algoritmos

- ‚úÖ M√°quina de estados de hotkey √© robusta
- ‚ö†Ô∏è Sem VAD (Voice Activity Detection) para auto-stop
- ‚ö†Ô∏è Sem streaming support (one-shot apenas)

### Score Geral: 6/10

**Implementado bem:** Transforma√ß√µes de dados, provedor abstra√ß√£o, UI customiza√ß√£o
**Fraco:** Valida√ß√µes de entrada, error handling, edge cases

**Prioridades de Melhoria:**
1. Adicionar schema validation (Zod) para config
2. Implementar retry + timeout para APIs
3. Adicionar valida√ß√µes de tamanho de √°udio
4. Teste de API key na settings

---

## AP√äNDICE: Pseudoc√≥digo de Valida√ß√µes Recomendadas

```typescript
// recommended-validations.ts

// V2: URL Validation
function validateApiUrl(url: string): boolean {
  try {
    const parsed = new URL(url)
    return ['https:', 'http:'].includes(parsed.protocol)
  } catch {
    return false
  }
}

// V5: API Key Format Validation
function validateApiKeyFormat(apiKey: string, provider: 'openai' | 'groq' | 'gemini'): boolean {
  const patterns = {
    openai: /^sk-[a-zA-Z0-9]{48,}$/,
    groq: /^gsk_[a-zA-Z0-9]{40,}$/,
    gemini: /^[a-zA-Z0-9_-]{40,}$/  // Approximate
  }
  return patterns[provider].test(apiKey)
}

// V6: API Key Connectivity Test
async function testApiKey(apiKey: string, provider: 'openai' | 'groq'): Promise<boolean> {
  const baseUrl = provider === 'groq' 
    ? 'https://api.groq.com/openai/v1'
    : 'https://api.openai.com/v1'
  
  try {
    const response = await fetch(`${baseUrl}/models`, {
      headers: { Authorization: `Bearer ${apiKey}` },
      timeout: 5000
    })
    return response.status === 200
  } catch {
    return false
  }
}

// V7-V8: Audio Size Validation
function validateAudioSize(blob: Blob, durationMs: number): {valid: boolean, error?: string} {
  const maxSizeBytes = 20 * 1024 * 1024  // 20 MB
  const minDurationMs = 500  // 0.5 seconds
  const maxDurationMs = 60000  // 60 seconds
  
  if (blob.size > maxSizeBytes) {
    return {valid: false, error: `Audio file too large (${blob.size / 1024 / 1024}MB, max 20MB)`}
  }
  if (durationMs < minDurationMs) {
    return {valid: false, error: `Recording too short (${durationMs}ms, min 500ms)`}
  }
  if (durationMs > maxDurationMs) {
    return {valid: false, error: `Recording too long (${durationMs}ms, max 60000ms)`}
  }
  
  return {valid: true}
}

// V9: Prompt Validation
function validateLLMPrompt(prompt: string): {valid: boolean, errors: string[]} {
  const errors: string[] = []
  
  if (!prompt.includes("{transcript}")) {
    errors.push("Prompt must include {transcript} placeholder")
  }
  if (prompt.length > 2000) {
    errors.push(`Prompt too long (${prompt.length} chars, max 2000)`)
  }
  if (prompt.trim().length === 0) {
    errors.push("Prompt cannot be empty")
  }
  
  return {
    valid: errors.length === 0,
    errors
  }
}

// V11: Client-Side Rate Limiting
class TranscriptionQueue {
  private isProcessing = false
  private queue: Array<{blob: Blob, duration: number}> = []
  
  async transcribe(blob: Blob, duration: number): Promise<string> {
    return new Promise((resolve, reject) => {
      this.queue.push({blob, duration})
      this.processQueue()
    })
  }
  
  private async processQueue() {
    if (this.isProcessing || this.queue.length === 0) return
    
    this.isProcessing = true
    const {blob, duration} = this.queue.shift()!
    
    try {
      const result = await tipcClient.createRecording({
        recording: await blob.arrayBuffer(),
        duration
      })
      // resolve(result)
    } finally {
      this.isProcessing = false
      this.processQueue()  // Process next in queue
    }
  }
}
```

---

**Documento Completo da FASE 4 Finalizado.**
**Total de Regras de Neg√≥cio Documentadas: 20+ (4 implementadas, 16 recomendadas)**
